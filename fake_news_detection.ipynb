{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12de9ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import time\n",
    "from typing import Set, List\n",
    "\n",
    "import warnings\n",
    "from abc import ABC, abstractmethod\n",
    "from enum import Enum\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, PassiveAggressiveClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b8b561",
   "metadata": {},
   "source": [
    "#### PART 1:  Cleaner functionality\n",
    "The following methods are designed to cleanup different parts of a given input text. The `clean_text`-method combines all the necessasy mehtods to cleanup the text as much as possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a88e9137",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_all_punctuations() -> Set[str]:\n",
    "    stop = set(stopwords.words(\"english\"))\n",
    "    all_punctuations = list(string.punctuation)\n",
    "    stop.update(all_punctuations)\n",
    "    return stop\n",
    "\n",
    "\n",
    "def strip_html(text: str) -> str:\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "\n",
    "def remove_urls(text: str) -> str:\n",
    "    return re.sub(r'http\\S+', '', text)\n",
    "\n",
    "\n",
    "def remove_between_square_brackets(text: str) -> str:\n",
    "    return re.sub('\\[[^]]*\\]', '', text)\n",
    "\n",
    "\n",
    "def remove_numbers(text: str) -> str:\n",
    "    return re.sub('\\w*\\d\\w*', '', text)\n",
    "\n",
    "\n",
    "def remove_stopwords(text: str) -> str:\n",
    "    _punctuations = ['\\\\', '`', '*', '_', '{', '}', '[', ']', '(', ')', '/', '“', '”', '’', '‘', '>', '@', '#', '+',\n",
    "                     '-', '--', '?', '%', '#', '£', '.', ':', ';', ',', '!', '$', '\\'']\n",
    "    stops = get_all_punctuations()\n",
    "    final_text = []\n",
    "    for i in text.split():\n",
    "        if i.strip().lower() not in stops:\n",
    "            for ch in _punctuations:\n",
    "                if ch in i:\n",
    "                    i = i.replace(ch, \" \")\n",
    "            final_text.append(i.strip())\n",
    "    return \" \".join(final_text)\n",
    "\n",
    "\n",
    "\n",
    "def remove_accent_signs(text: str) -> str:\n",
    "    return re.sub('[‘’“”…]', '', text)\n",
    "\n",
    "\n",
    "def remove_new_lines(text: str) -> str:\n",
    "    return re.sub('\\n', '', text)\n",
    "\n",
    "\n",
    "def tokenize(text: str) -> List[str]:\n",
    "    split = re.split(\"\\W+\", text)\n",
    "    return split\n",
    "\n",
    "\n",
    "def lemmatizer(text: List[str]) -> List[str]:\n",
    "    wl = WordNetLemmatizer()\n",
    "    return [wl.lemmatize(word) for word in text if word not in set(stopwords.words('english'))]\n",
    "\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    text = strip_html(text)\n",
    "    text = text.lower()\n",
    "    text = remove_between_square_brackets(text)\n",
    "    text = remove_urls(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = remove_numbers(text)\n",
    "    text = remove_accent_signs(text)\n",
    "    text = remove_new_lines(text)\n",
    "    text = tokenize(text)\n",
    "    text = lemmatizer(text)\n",
    "    return ' '.join(i for i in text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4136f9",
   "metadata": {},
   "source": [
    "#### PART 2: Train test split\n",
    "The class below encapsulates and keeps track of train and test parts of the text and categories. We split the data 80/20 between train and test model, where 80% goes to train the model and use the remaining 20% to test the trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b96634a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainTestSplit:\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df\n",
    "        text = self.df.text\n",
    "        category = self.df.category\n",
    "        self.text_train, self.text_test, self.category_train, self.category_test = train_test_split(text,\n",
    "                                                                                                    category,\n",
    "                                                                                                    train_size=.8,\n",
    "                                                                                                    stratify=category,\n",
    "                                                                                                    random_state=19)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c609e8",
   "metadata": {},
   "source": [
    "#### PART 3: Vectorization\n",
    " In this project, two different vectorization techniques are utilized. Therefore, an enum/enumeration-class is constructed to keep track of the type of vectorization. In addition, a `Vectorize`-class is created to build an object of the given vectorizer type, which is used to convert train data into numerical numbers representing the frequency of each token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05a37fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorizerType(Enum):\n",
    "    Tfidf = 0\n",
    "    Count = 1\n",
    "\n",
    "\n",
    "class Vectorize:\n",
    "    def __init__(self, split: TrainTestSplit, vectorizer_type: VectorizerType):\n",
    "        self.split = split\n",
    "\n",
    "        if vectorizer_type == VectorizerType.Tfidf:\n",
    "            self._vectorizer = TfidfVectorizer(min_df=0, max_df=1, use_idf=True, ngram_range=(1, 3))\n",
    "        elif vectorizer_type is VectorizerType.Count:\n",
    "            self._vectorizer = CountVectorizer(min_df=0, max_df=1, binary=False, ngram_range=(1, 3))\n",
    "        else:\n",
    "            raise RuntimeError(\"Unable to determine the vectorizer type.\")\n",
    "\n",
    "        self.train = self._vectorizer.fit_transform(self.split.text_train)\n",
    "        self.test = self._vectorizer.transform(self.split.text_test)\n",
    "\n",
    "        msg = \"TF-IDF\" if vectorizer_type == VectorizerType.Tfidf else \"Count\"\n",
    "        print(f\"{msg} Train: {self.train.shape}\")\n",
    "        print(f\"{msg} Test: {self.test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfade06",
   "metadata": {},
   "source": [
    "#### PART 4: Text processor\n",
    "Given the input datasets, the class below starts the orchestriation of all the necassery objects, such as the dataframe, vectorizer, and train-test-split. In addition, it also handles the cleanup of the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5de7419c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextProcessor:\n",
    "    def __init__(self, true_news: str, fake_news: str, vectorizer_type: VectorizerType, sample_size: int = 1000):\n",
    "        self._df = None\n",
    "        self.true_news = pd.read_csv(true_news)\n",
    "        self.fake_news = pd.read_csv(fake_news)\n",
    "        self.vectorizer_type = vectorizer_type\n",
    "        self.sample_size = sample_size\n",
    "\n",
    "        self._split = None\n",
    "        self._vectorize = None\n",
    "\n",
    "    def create_data_frame(self) -> pd.DataFrame:\n",
    "        self.true_news[\"category\"] = 1\n",
    "        self.fake_news[\"category\"] = 0\n",
    "\n",
    "        df = pd.concat([self.true_news, self.fake_news], axis=0)\n",
    "        df = df.drop([\"title\", \"subject\", \"date\"], axis=1)\n",
    "\n",
    "        df.reset_index(inplace=True)\n",
    "        df.drop([\"index\"], axis=1, inplace=True)\n",
    "\n",
    "        return df.sample(frac=1).head(self.sample_size)\n",
    "\n",
    "    @property\n",
    "    def df(self) -> pd.DataFrame:\n",
    "        if self._df is None:\n",
    "            self._df = self.create_data_frame()\n",
    "        return self._df\n",
    "\n",
    "    def cleanup_text(self) -> None:\n",
    "        self.df['text'] = self.df['text'].apply(clean_text)\n",
    "\n",
    "    def pre_processor(self) -> None:\n",
    "        self.create_data_frame()\n",
    "        self.cleanup_text()\n",
    "\n",
    "    @property\n",
    "    def split(self) -> TrainTestSplit:\n",
    "        if self._split is None:\n",
    "            self._split = TrainTestSplit(self.df)\n",
    "        return self._split\n",
    "\n",
    "    @property\n",
    "    def vectorize(self):\n",
    "        if self._vectorize is None:\n",
    "            self._vectorize = Vectorize(split=self.split, vectorizer_type=self.vectorizer_type)\n",
    "        return self._vectorize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731e2420",
   "metadata": {},
   "source": [
    "#### PART 5: Model\n",
    "`ModelType`: an enumuration class containing all the supported models in this project.\n",
    "\n",
    "The `create_model`-method is a helper method which is used to instantiate a model object based on the input model type. So e.g., if the model type is `ModelType.nb`, then it creates and returns an object of `MultinomialNB` class.\n",
    "\n",
    "The `Model`-class inherets all the functionality of `TextProcessor`-class. Meaning it is able to cleanup the input text, split the input into traning and testing parts, as well as, vectorizing the text. The `Model`-class uses the `create_model` to get the appropriate object representing the requested input model type. Once the model object is constructed, it's capable of performing a traning on the dataset and predict based on the test data input. The `Model`-class has also the funtionality to measure the accuracy score, as well as generating a classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "187b99be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelType(Enum):\n",
    "    nb = \"MultinomialNBModel\"\n",
    "    lr = \"LogisticRegressionModel\"\n",
    "    pa = \"PassiveAggressiveClassifier\"\n",
    "    dt = \"DecisionTreeClassifier\"\n",
    "\n",
    "\n",
    "def create_model(model_type: ModelType):\n",
    "    if model_type == ModelType.nb:\n",
    "        return MultinomialNB()\n",
    "    elif model_type == ModelType.lr:\n",
    "        return LogisticRegression()\n",
    "    elif model_type == ModelType.pa:\n",
    "        return PassiveAggressiveClassifier(C=0.5, random_state=5)\n",
    "    elif model_type == ModelType.dt:\n",
    "        return DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "class Model(TextProcessor):\n",
    "    def __init__(self, true_news: str, fake_news: str, vectorizer_type: VectorizerType, model_type: ModelType,\n",
    "                 sample_size: int = 1000):\n",
    "        super().__init__(true_news, fake_news, vectorizer_type, sample_size)\n",
    "        self.model_type = model_type\n",
    "        self.model = create_model(self.model_type)\n",
    "\n",
    "        self._score = None\n",
    "\n",
    "    def fit(self):\n",
    "        self.model.fit(self.vectorize.train, self.split.category_train)\n",
    "\n",
    "    def predict(self):\n",
    "        return self.model.predict(self.vectorize.test)\n",
    "\n",
    "    @property\n",
    "    def accuracy_score(self):\n",
    "        if self._score is None:\n",
    "            self._score = accuracy_score(self.split.category_test, self.predict())\n",
    "        return self._score\n",
    "    \n",
    "    def print_accuracy_score(self) -> None:\n",
    "        msg = \"TF-IDF\" if self.vectorizer_type == VectorizerType.Tfidf else \"Count\"\n",
    "        print(f\"{self.model_type.value} {msg} accuracy score:  {round(self.accuracy_score * 100, 2)}%\")\n",
    "\n",
    "    def print_classification_report(self) -> None:\n",
    "        report = classification_report(self.split.category_test, self.predict(), target_names=['0', '1'])\n",
    "        print(report)\n",
    "\n",
    "    def run(self):\n",
    "        self.pre_processor()  # cleans the text\n",
    "        self.fit() # training the model\n",
    "\n",
    "        self.print_accuracy_score()\n",
    "        self.print_classification_report()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e59b4eb",
   "metadata": {},
   "source": [
    "#### PART 6: Orchestration and running the model\n",
    "Below, we have a helper method, which takes input fake and true news files, as well as a sample size and an input model type. The method is used to run the specified model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "addd6838",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(true_news: str, fake_news: str, sample_size: int, model_type: ModelType):\n",
    "    vectorizer_types = [VectorizerType.Tfidf, VectorizerType.Count]\n",
    "    for vectorizer_type in vectorizer_types:\n",
    "        tic = time.perf_counter()\n",
    "        m = Model(true_news=true_news, fake_news=fake_news, vectorizer_type=vectorizer_type,\n",
    "                  model_type=model_type, sample_size=sample_size)\n",
    "        m.run()\n",
    "        print(f\"Execution time for {float(time.perf_counter()-tic):0.2f}\")\n",
    "        print()\n",
    "        print(\"------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bef0a8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to input files:\n",
    "true_news_file = 'True.csv'\n",
    "fake_news_file = 'Fake.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba535229",
   "metadata": {},
   "source": [
    "#### MultinominalNBModel\n",
    "Runs the Naïve Bayse model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a12b006b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Train: (80, 36907)\n",
      "TF-IDF Test: (20, 36907)\n",
      "MultinomialNBModel TF-IDF accuracy score:  55.0%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       0.55      1.00      0.71        11\n",
      "\n",
      "    accuracy                           0.55        20\n",
      "   macro avg       0.28      0.50      0.35        20\n",
      "weighted avg       0.30      0.55      0.39        20\n",
      "\n",
      "Execution time for 10.41\n",
      "\n",
      "------------------------------------------------------\n",
      "Count Train: (80, 37420)\n",
      "Count Test: (20, 37420)\n",
      "MultinomialNBModel Count accuracy score:  70.0%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67         9\n",
      "           1       0.73      0.73      0.73        11\n",
      "\n",
      "    accuracy                           0.70        20\n",
      "   macro avg       0.70      0.70      0.70        20\n",
      "weighted avg       0.70      0.70      0.70        20\n",
      "\n",
      "Execution time for 7.76\n",
      "\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "sample_size = 100\n",
    "model_type = ModelType.nb\n",
    "\n",
    "run_model(true_news=true_news_file, fake_news=fake_news_file, sample_size=sample_size, model_type=model_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff388452",
   "metadata": {},
   "source": [
    "#### Logistic regression Model\n",
    "Runs the Logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c510123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Train: (80, 34391)\n",
      "TF-IDF Test: (20, 34391)\n",
      "LogisticRegressionModel TF-IDF accuracy score:  55.0%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      1.00      0.71        11\n",
      "           1       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.55        20\n",
      "   macro avg       0.28      0.50      0.35        20\n",
      "weighted avg       0.30      0.55      0.39        20\n",
      "\n",
      "Execution time for 7.45\n",
      "\n",
      "------------------------------------------------------\n",
      "Count Train: (80, 36093)\n",
      "Count Test: (20, 36093)\n",
      "LogisticRegressionModel Count accuracy score:  55.0%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      1.00      0.69        10\n",
      "           1       1.00      0.10      0.18        10\n",
      "\n",
      "    accuracy                           0.55        20\n",
      "   macro avg       0.76      0.55      0.44        20\n",
      "weighted avg       0.76      0.55      0.44        20\n",
      "\n",
      "Execution time for 8.29\n",
      "\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "sample_size = 100\n",
    "model_type = ModelType.lr\n",
    "\n",
    "run_model(true_news=true_news_file, fake_news=fake_news_file, sample_size=sample_size, model_type=model_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78217a9",
   "metadata": {},
   "source": [
    "#### Passive Aggressive Classifier Model\n",
    "Runs the PassiveAggressiveClassifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a5fc6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Train: (80, 35623)\n",
      "TF-IDF Test: (20, 35623)\n",
      "PassiveAggressiveClassifier TF-IDF accuracy score:  65.0%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.92      0.76        12\n",
      "           1       0.67      0.25      0.36         8\n",
      "\n",
      "    accuracy                           0.65        20\n",
      "   macro avg       0.66      0.58      0.56        20\n",
      "weighted avg       0.65      0.65      0.60        20\n",
      "\n",
      "Execution time for 8.40\n",
      "\n",
      "------------------------------------------------------\n",
      "Count Train: (80, 41981)\n",
      "Count Test: (20, 41981)\n",
      "PassiveAggressiveClassifier Count accuracy score:  75.0%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78        11\n",
      "           1       0.75      0.67      0.71         9\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.75      0.74      0.74        20\n",
      "weighted avg       0.75      0.75      0.75        20\n",
      "\n",
      "Execution time for 9.40\n",
      "\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "sample_size = 100\n",
    "model_type = ModelType.pa\n",
    "\n",
    "run_model(true_news=true_news_file, fake_news=fake_news_file, sample_size=sample_size, model_type=model_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5715ee",
   "metadata": {},
   "source": [
    "#### Decision Tree Classifier Model\n",
    "Runs the DecisionTreeClassifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7315749b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Train: (80, 34937)\n",
      "TF-IDF Test: (20, 34937)\n",
      "DecisionTreeClassifier TF-IDF accuracy score:  60.0%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      1.00      0.73        11\n",
      "           1       1.00      0.11      0.20         9\n",
      "\n",
      "    accuracy                           0.60        20\n",
      "   macro avg       0.79      0.56      0.47        20\n",
      "weighted avg       0.77      0.60      0.49        20\n",
      "\n",
      "Execution time for 7.84\n",
      "\n",
      "------------------------------------------------------\n",
      "Count Train: (80, 42207)\n",
      "Count Test: (20, 42207)\n",
      "DecisionTreeClassifier Count accuracy score:  55.0%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      1.00      0.69        10\n",
      "           1       1.00      0.10      0.18        10\n",
      "\n",
      "    accuracy                           0.55        20\n",
      "   macro avg       0.76      0.55      0.44        20\n",
      "weighted avg       0.76      0.55      0.44        20\n",
      "\n",
      "Execution time for 8.58\n",
      "\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "sample_size = 100\n",
    "model_type = ModelType.dt\n",
    "\n",
    "run_model(true_news=true_news_file, fake_news=fake_news_file, sample_size=sample_size, model_type=model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9370b47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
